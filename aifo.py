# aifo.py
# AI File Organizer CLI - Updated with Gemma ONNX Support
# 
# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜:
# pip install pdfplumber python-docx python-pptx openpyxl olefile

import argparse
import datetime
import os
import re
import shutil
import sys
from pathlib import Path

# --- AI ëª¨ë“ˆ Import ---
# ai_module.pyê°€ ê°™ì€ í´ë”ì— ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
try:
    from ai_module import AIKeywordExtractor
except ImportError:
    print("ì˜¤ë¥˜: 'ai_module.py' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìŠ¤í¬ë¦½íŠ¸ì™€ ê°™ì€ í´ë”ì— ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
    sys.exit(1)

# --- ì„¤ì • (Configuration) ---

# ëª¨ë¸ ê²½ë¡œ (ì‚¬ìš©ìê°€ ìˆ˜ì •í•´ì•¼ í•˜ëŠ” ë¶€ë¶„)
DEFAULT_MODEL_PATH = "gemma-3n-E2B-it-ONNX"

# ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
DEFAULT_PROMPT_TEMPLATE = """You are an expert file naming specialist. Your sole task is to generate new filenames based on file content and original filename.

TASK: Generate a single, optimized filename that accurately represents the file's content.

GUIDELINES:
- Length: 3-8 words maximum
- Format: Use underscores instead of spaces
- Include file extension from original filename
- Be descriptive but concise
- Use common, clear terminology
- Avoid special characters except underscores and periods

INPUT FORMAT:
Original filename: [filename]
File content: [content]

OUTPUT FORMAT:
Provide ONLY the new filename. No explanations, no additional text.

EXAMPLES:
Original filename: document1.pdf
File content: This is a quarterly sales report for Q3 2024 showing revenue growth of 15%
Output: Q3_2024_sales_report.pdf

Original filename: IMG_20240315.jpg
File content: Photo of a golden retriever playing in a park during sunset
Output: golden_retriever_sunset_park.jpg

Original filename: notes.txt
File content: Meeting notes from project kickoff discussing timeline, budget allocation, and team responsibilities
Output: project_kickoff_meeting_notes.txt

Now process the following file:
---
{file_content}
---
"""

# íŒŒì¼ ë¶„ë¥˜ ê·œì¹™
FILE_CATEGORIES = {
    'ë¬¸ì„œ': ['.pdf', '.docx', '.pptx', '.hwp', '.txt', '.md'],
    'ìŠ¤í”„ë ˆë“œì‹œíŠ¸': ['.xlsx', '.xls', '.csv'],
    'ì´ë¯¸ì§€': ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff'],
    'ë™ì˜ìƒ': ['.mp4', '.avi', '.mkv', '.mov', '.wmv'],
    'ìŒì•…': ['.mp3', '.wav', '.flac', '.m4a'],
    'ì••ì¶•íŒŒì¼': ['.zip', '.7z', '.rar', '.tar', '.gz'],
    'ì½”ë“œ': ['.py', '.js', '.html', '.css', '.java', '.cpp', '.c'],
    'ê¸°íƒ€': 'others'
}

# AI ì²˜ë¦¬ ëŒ€ìƒ íŒŒì¼ í™•ì¥ì
AI_SUPPORTED_EXTENSIONS = ['.txt', '.md', '.pdf', '.docx', '.pptx', '.hwp', '.xlsx', '.xls']
# ì´ë¯¸ì§€ AI ì²˜ë¦¬ ëŒ€ìƒ íŒŒì¼ í™•ì¥ì
AI_SUPPORTED_IMAGE_EXTENSIONS = ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff']
# ì˜¤ë””ì˜¤ AI ì²˜ë¦¬ ëŒ€ìƒ íŒŒì¼ í™•ì¥ì
AI_SUPPORTED_AUDIO_EXTENSIONS = ['.mp3', '.wav', '.flac', '.m4a', '.ogg', '.aac']

# ì œì™¸í•  íŒŒì¼/í´ë” ëª©ë¡
EXCLUDE_PATTERNS = [
    '.git', '.DS_Store', 'node_modules', 'venv', '__pycache__',
    'Thumbs.db', '.vscode', '.idea', 'aifo.log'
]

# ë¡œê·¸ íŒŒì¼ëª…
LOG_FILE_NAME = "aifo.log"

# AI Extractor ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì „ì—­ìœ¼ë¡œ ê´€ë¦¬ (Lazy Loading)
AI_EXTRACTOR: AIKeywordExtractor | None = None

# --- ë¬¸ì„œ ì½ê¸° í•¨ìˆ˜ ---

def extract_text_from_file(file_path: Path) -> str:
    """íŒŒì¼ í˜•ì‹ì— ë”°ë¼ ì ì ˆí•œ ë°©ë²•ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    ext = file_path.suffix.lower()
    
    try:
        if ext == '.pdf':
            try:
                import pdfplumber
                with pdfplumber.open(file_path) as pdf:
                    text = ""
                    for page in pdf.pages:
                        page_text = page.extract_text()
                        if page_text:
                            text += page_text + "\n"
                    return text
            except ImportError:
                print("ê²½ê³ : pdfplumberê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install pdfplumberë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
                return ""
                
        elif ext == '.docx':
            try:
                from docx import Document
                doc = Document(file_path)
                text = ""
                for paragraph in doc.paragraphs:
                    text += paragraph.text + "\n"
                return text
            except ImportError:
                print("ê²½ê³ : python-docxê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install python-docxë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
                return ""
            
        elif ext == '.pptx':
            try:
                from pptx import Presentation
                prs = Presentation(file_path)
                text = ""
                for slide in prs.slides:
                    for shape in slide.shapes:
                        if hasattr(shape, "text") and shape.text.strip():
                            text += shape.text + "\n"
                        # í‘œ ë‚´ìš©ë„ ì¶”ì¶œ
                        if shape.has_table:
                            for row in shape.table.rows:
                                for cell in row.cells:
                                    if cell.text.strip():
                                        text += cell.text + " "
                                text += "\n"
                return text
            except ImportError:
                print("ê²½ê³ : python-pptxê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install python-pptxë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
                return ""
            except Exception as e:
                print(f"ê²½ê³ : PPTX íŒŒì¼ '{file_path.name}' ì½ê¸°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
                return ""
                
        elif ext in ['.xlsx', '.xls']:
            try:
                import openpyxl
                workbook = openpyxl.load_workbook(file_path, data_only=True)
                text = ""
                for sheet_name in workbook.sheetnames:
                    sheet = workbook[sheet_name]
                    text += f"[ì‹œíŠ¸: {sheet_name}]\n"
                    for row in sheet.iter_rows(values_only=True):
                        row_text = []
                        for cell in row:
                            if cell is not None:
                                row_text.append(str(cell))
                        if row_text and any(cell.strip() for cell in row_text if isinstance(cell, str)):
                            text += " | ".join(row_text) + "\n"
                    text += "\n"
                return text
            except ImportError:
                print("ê²½ê³ : openpyxlì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install openpyxlë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
                return ""
            except Exception as e:
                print(f"ê²½ê³ : Excel íŒŒì¼ '{file_path.name}' ì½ê¸°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
                return ""
                
        elif ext == '.hwp':
            try:
                # ë¨¼ì € olefileì„ ì‚¬ìš©í•´ì„œ HWP íŒŒì¼ ì½ê¸° ì‹œë„
                import olefile
                if olefile.isOleFile(file_path):
                    ole = olefile.OleFileIO(file_path)
                    # HWP íŒŒì¼ì˜ í…ìŠ¤íŠ¸ ìŠ¤íŠ¸ë¦¼ ì°¾ê¸°
                    if ole._olestream_size is not None:
                        # ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ì™„ì „í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ)
                        with open(file_path, 'rb') as f:
                            data = f.read()
                            # í•œê¸€ í…ìŠ¤íŠ¸ íŒ¨í„´ ì°¾ê¸° (ë§¤ìš° ê¸°ë³¸ì ì¸ ë°©ë²•)
                            text_parts = []
                            try:
                                # UTF-16ìœ¼ë¡œ ë””ì½”ë”© ì‹œë„
                                decoded = data.decode('utf-16le', errors='ignore')
                                # ì˜ë¯¸ìˆëŠ” í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
                                import re
                                korean_text = re.findall(r'[ê°€-í£\s]+', decoded)
                                text_parts.extend([t.strip() for t in korean_text if len(t.strip()) > 2])
                            except:
                                pass
                            
                            try:
                                # UTF-8ë¡œë„ ì‹œë„
                                decoded = data.decode('utf-8', errors='ignore')
                                korean_text = re.findall(r'[ê°€-í£\s]+', decoded)
                                text_parts.extend([t.strip() for t in korean_text if len(t.strip()) > 2])
                            except:
                                pass
                            
                        ole.close()
                        return "\n".join(text_parts[:100])  # ìƒìœ„ 100ê°œ í…ìŠ¤íŠ¸ ë¶€ë¶„ë§Œ
                    ole.close()
            except ImportError:
                print("ê²½ê³ : olefileì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install olefileë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
                return ""
            except Exception as e:
                print(f"ê²½ê³ : HWP íŒŒì¼ '{file_path.name}' ì½ê¸°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
                return ""
            return ""
                
        elif ext in ['.txt', '.md']:
            return file_path.read_text(encoding='utf-8', errors='ignore')
            
        else:
            # ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹ì€ í…ìŠ¤íŠ¸ë¡œ ì½ê¸° ì‹œë„
            try:
                return file_path.read_text(encoding='utf-8', errors='ignore')
            except:
                return ""
            
    except Exception as e:
        print(f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜ ({file_path.name}): {e}")
        return ""

# --- ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ---

def get_file_category(file_ext: str) -> str:
    """íŒŒì¼ í™•ì¥ìì— ë”°ë¥¸ ì¹´í…Œê³ ë¦¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    file_ext = file_ext.lower()
    for category, extensions in FILE_CATEGORIES.items():
        if category == 'ê¸°íƒ€':
            continue
        if file_ext in extensions:
            return category
    return 'ê¸°íƒ€'

def should_exclude_file(file_path: Path) -> bool:
    """íŒŒì¼ì´ ì œì™¸ ëŒ€ìƒì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
    # íŒŒì¼ëª… ì²´í¬
    if file_path.name in EXCLUDE_PATTERNS:
        return True
    
    # ê²½ë¡œì— ì œì™¸ íŒ¨í„´ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ ì²´í¬
    for part in file_path.parts:
        if part in EXCLUDE_PATTERNS:
            return True
    
    return False

# --- AI ëª¨ë“ˆ ì—°ë™ í•¨ìˆ˜ ---

def initialize_ai_module(model_path: str = None, prompt_template: str = None) -> AIKeywordExtractor | None:
    """
    AI ëª¨ë“ˆì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
    ì´ˆê¸°í™”ëŠ” í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì¤‘ í•œ ë²ˆë§Œ ìˆ˜í–‰ë©ë‹ˆë‹¤.
    """
    global AI_EXTRACTOR
    if AI_EXTRACTOR is not None:
        return AI_EXTRACTOR

    # ê¸°ë³¸ê°’ ì‚¬ìš©
    model_path = model_path or DEFAULT_MODEL_PATH
    prompt_template = prompt_template or DEFAULT_PROMPT_TEMPLATE

    model_path_obj = Path(model_path)
    if not model_path_obj.is_dir():
        print(f"ì˜¤ë¥˜: ëª¨ë¸ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”: {model_path_obj}")
        print(f"íŒíŠ¸: í˜„ì¬ ì„¤ì •ëœ ëª¨ë¸ ê²½ë¡œëŠ” '{DEFAULT_MODEL_PATH}' ì…ë‹ˆë‹¤.")
        print("      ë‹¤ë¥¸ ê²½ë¡œë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ --model-path ì˜µì…˜ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
        return None

    print("ğŸ§  Gemma ONNX ëª¨ë¸ì„ ë¡œë”©í•©ë‹ˆë‹¤. ì ì‹œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...")
    try:
        AI_EXTRACTOR = AIKeywordExtractor(
            model_path=str(model_path_obj),
            prompt_template=prompt_template
        )
        print("âœ… AI ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
        return AI_EXTRACTOR
    except Exception as e:
        print(f"ì˜¤ë¥˜: AI ëª¨ë¸ ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ({e})")
        print("ONNX Runtimeê³¼ transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì¹˜ë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return None


def get_ai_keywords_from_file(file_path: Path) -> str:
    """
    ì£¼ì–´ì§„ íŒŒì¼ì˜ ë‚´ìš©ì„ AI ëª¨ë“ˆì— ì „ë‹¬í•˜ì—¬ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ë°˜í™˜ë°›ìŠµë‹ˆë‹¤.
    """
    if AI_EXTRACTOR is None:
        return "AI_ëª¨ë“ˆ_ì´ˆê¸°í™”_ì‹¤íŒ¨"

    print(f"ğŸ§  AI: '{file_path.name}' íŒŒì¼ ë‚´ìš© ë¶„ì„ ì¤‘...")
    try:
        ext = file_path.suffix.lower()
        
        # ì˜¤ë””ì˜¤ íŒŒì¼ì¸ ê²½ìš°
        if ext in AI_SUPPORTED_AUDIO_EXTENSIONS:
            if not file_path.exists():
                return "íŒŒì¼ì—†ìŒ"
            keywords = AI_EXTRACTOR.extract_keywords("", file_path.name, audio_path=str(file_path))
        # ì´ë¯¸ì§€ íŒŒì¼ì¸ ê²½ìš°
        elif ext in AI_SUPPORTED_IMAGE_EXTENSIONS:
            if not file_path.exists():
                return "íŒŒì¼ì—†ìŒ"
            keywords = AI_EXTRACTOR.extract_keywords("", file_path.name, str(file_path))
        # í…ìŠ¤íŠ¸ íŒŒì¼ì¸ ê²½ìš°
        elif ext in AI_SUPPORTED_EXTENSIONS:
            content = extract_text_from_file(file_path)
            if not content.strip():
                return "ë‚´ìš©ì—†ìŒ"
            keywords = AI_EXTRACTOR.extract_keywords(content, file_path.name)
        else:
            return "ì§€ì›í•˜ì§€ì•ŠëŠ”í˜•ì‹"
        
        # íŒŒì¼ëª…ìœ¼ë¡œ ë¶€ì ì ˆí•œ ë¬¸ì ì œê±°
        safe_keywords = "".join(c for c in keywords if c.isalnum() or c in ['_', '-'])
        
        # í‚¤ì›Œë“œê°€ ë„ˆë¬´ ì§§ê±°ë‚˜ ì˜ë¯¸ì—†ìœ¼ë©´ íŒŒì¼ëª… ê¸°ë°˜ìœ¼ë¡œ ëŒ€ì²´
        if not safe_keywords or safe_keywords in ["í‚¤ì›Œë“œì¶”ì¶œì‹¤íŒ¨", "ë‚´ìš©ì—†ìŒ", "ì§€ì›í•˜ì§€ì•ŠëŠ”í˜•ì‹", "ì˜¤ë””ì˜¤_ë¶„ì„ë¶ˆê°€_ì˜¤ë””ì˜¤ëª¨ë¸ì—†ìŒ"] or len(safe_keywords) < 3:
            # íŒŒì¼ëª…ì—ì„œ ì˜ë¯¸ìˆëŠ” ë¶€ë¶„ ì¶”ì¶œ
            name_parts = re.findall(r'[ê°€-í£A-Za-z]+', file_path.stem)
            if name_parts:
                safe_keywords = '_'.join(name_parts[:3])  # ìµœëŒ€ 3ê°œ ë‹¨ì–´
            else:
                safe_keywords = "ë¶„ë¥˜í•„ìš”"
        
        return safe_keywords

    except Exception as e:
        print(f"ì˜¤ë¥˜: '{file_path.name}' íŒŒì¼ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return "í‚¤ì›Œë“œì¶”ì¶œì‹¤íŒ¨"


def get_ai_filename_suggestion(file_path: Path) -> str:
    """
    AIë¥¼ ì‚¬ìš©í•˜ì—¬ íŒŒì¼ ë‚´ìš© ê¸°ë°˜ìœ¼ë¡œ ìƒˆë¡œìš´ íŒŒì¼ëª…ì„ ì œì•ˆë°›ìŠµë‹ˆë‹¤.
    """
    if AI_EXTRACTOR is None:
        return file_path.name

    print(f"ğŸ¤– AI: '{file_path.name}' íŒŒì¼ëª… ì œì•ˆ ì¤‘...")
    try:
        ext = file_path.suffix.lower()
        original_name = file_path.stem
        extension = file_path.suffix
        
        # ì˜¤ë””ì˜¤ íŒŒì¼ì¸ ê²½ìš°
        if ext in AI_SUPPORTED_AUDIO_EXTENSIONS:
            if not file_path.exists():
                return file_path.name
            suggested_name = AI_EXTRACTOR.suggest_filename("", original_name, extension, audio_path=str(file_path))
        # ì´ë¯¸ì§€ íŒŒì¼ì¸ ê²½ìš°
        elif ext in AI_SUPPORTED_IMAGE_EXTENSIONS:
            if not file_path.exists():
                return file_path.name
            suggested_name = AI_EXTRACTOR.suggest_filename("", original_name, extension, str(file_path))
        # í…ìŠ¤íŠ¸ íŒŒì¼ì¸ ê²½ìš°
        elif ext in AI_SUPPORTED_EXTENSIONS:
            content = extract_text_from_file(file_path)
            if not content.strip():
                return file_path.name
            suggested_name = AI_EXTRACTOR.suggest_filename(content, original_name, extension)
        else:
            return file_path.name
        
        return suggested_name

    except Exception as e:
        print(f"ì˜¤ë¥˜: '{file_path.name}' íŒŒì¼ëª… ì œì•ˆ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return file_path.name


def get_ai_folder_classification(file_path: Path) -> str:
    """
    AIë¥¼ ì‚¬ìš©í•˜ì—¬ íŒŒì¼ ë‚´ìš©ì„ ë¶„ì„í•˜ê³  ì ì ˆí•œ í´ë”ë¥¼ ë¶„ë¥˜í•©ë‹ˆë‹¤.
    """
    if AI_EXTRACTOR is None:
        return "ê¸°íƒ€"

    print(f"ğŸ“ AI: '{file_path.name}' í´ë” ë¶„ë¥˜ ì¤‘...")
    try:
        ext = file_path.suffix.lower()
        
        # ì˜¤ë””ì˜¤ íŒŒì¼ì¸ ê²½ìš°
        if ext in AI_SUPPORTED_AUDIO_EXTENSIONS:
            if not file_path.exists():
                return "ê¸°íƒ€"
            folder_name = AI_EXTRACTOR.classify_folder("", file_path.name, audio_path=str(file_path))
        # ì´ë¯¸ì§€ íŒŒì¼ì¸ ê²½ìš°
        elif ext in AI_SUPPORTED_IMAGE_EXTENSIONS:
            if not file_path.exists():
                return "ê¸°íƒ€"
            folder_name = AI_EXTRACTOR.classify_folder("", file_path.name, str(file_path))
        # í…ìŠ¤íŠ¸ íŒŒì¼ì¸ ê²½ìš°
        elif ext in AI_SUPPORTED_EXTENSIONS:
            content = extract_text_from_file(file_path)
            if not content.strip():
                return "ê¸°íƒ€"
            folder_name = AI_EXTRACTOR.classify_folder(content, file_path.name)
        else:
            return "ê¸°íƒ€"
        
        # í´ë”ëª…ìœ¼ë¡œ ë¶€ì ì ˆí•œ ë¬¸ì ì œê±°
        safe_folder_name = "".join(c for c in folder_name if c.isalnum() or c in ['_', '-', ' '])
        return safe_folder_name if safe_folder_name else "ê¸°íƒ€"

    except Exception as e:
        print(f"ì˜¤ë¥˜: '{file_path.name}' í´ë” ë¶„ë¥˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return "ê¸°íƒ€"

# --- í•µì‹¬ ë¡œì§ (Core Logic) ---

def organize_files(target_path: Path, model_path: str = None, dry_run: bool = False, 
                  recursive: bool = False, use_ai_keyword: bool = False, 
                  use_ai_filename: bool = False, use_ai_classify: bool = False, 
                  skip_confirm: bool = False, log_file: str = None):
    """íŒŒì¼ ì •ë¦¬ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""

    # AI ê¸°ëŠ¥ ì‚¬ìš© ì‹œ, ëª¨ë¸ ì´ˆê¸°í™”
    if use_ai_keyword or use_ai_filename or use_ai_classify:
        if not initialize_ai_module(model_path):
            sys.exit(1) # ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œ í”„ë¡œê·¸ë¨ ì¢…ë£Œ

    # 1. ì •ë¦¬í•  íŒŒì¼ ëª©ë¡ ìŠ¤ìº”
    print(f"ğŸ” '{target_path.resolve()}' ê²½ë¡œë¥¼ ìŠ¤ìº”í•©ë‹ˆë‹¤...")
    files_to_organize = []
    file_iterator = target_path.rglob('*') if recursive else target_path.glob('*')

    for item in file_iterator:
        if item.is_file() and not should_exclude_file(item):
            files_to_organize.append(item)

    if not files_to_organize:
        print("ì •ë¦¬í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 2. ë³€ê²½ ê³„íš ìˆ˜ë¦½
    change_plan = []
    for old_path in files_to_organize:
        new_name = old_path.name
        new_dir = old_path.parent

        original_name = old_path.stem
        ext = old_path.suffix.lower()
        date_created = datetime.datetime.fromtimestamp(old_path.stat().st_ctime).strftime('%Y-%m-%d')

        # 2-1. AI ê¸°ë°˜ íŒŒì¼ëª… ì™„ì „ ë³€ê²½
        if use_ai_filename and (ext in AI_SUPPORTED_EXTENSIONS or ext in AI_SUPPORTED_IMAGE_EXTENSIONS or ext in AI_SUPPORTED_AUDIO_EXTENSIONS):
            new_name = get_ai_filename_suggestion(old_path)
        
        # 2-2. AI í‚¤ì›Œë“œ ê¸°ë°˜ ì´ë¦„ ë³€ê²½
        elif use_ai_keyword and (ext in AI_SUPPORTED_EXTENSIONS or ext in AI_SUPPORTED_IMAGE_EXTENSIONS or ext in AI_SUPPORTED_AUDIO_EXTENSIONS):
            keywords = get_ai_keywords_from_file(old_path)
            if keywords and keywords not in ["í‚¤ì›Œë“œì¶”ì¶œì‹¤íŒ¨", "ë‚´ìš©ì—†ìŒ", "ì§€ì›í•˜ì§€ì•ŠëŠ”í˜•ì‹", "ì˜¤ë””ì˜¤_ë¶„ì„ë¶ˆê°€_ì˜¤ë””ì˜¤ëª¨ë¸ì—†ìŒ"]:
                new_name = f"{original_name}_{keywords}{ext}"
        
        # 2-3. ì¼ë°˜ ì´ë¦„ ë³€ê²½ ê·œì¹™ (í…ìŠ¤íŠ¸ íŒŒì¼ì—ë§Œ ë‚ ì§œ ì¶”ê°€)
        elif ext in ['.txt', '.md']:
            new_name = f"{date_created}_{original_name}{ext}"
        elif ext in ['.jpg', '.jpeg', '.png', '.gif']:
            new_name = f"IMG_{date_created}_{original_name}{ext}"
        elif ext in AI_SUPPORTED_AUDIO_EXTENSIONS:
            new_name = f"AUDIO_{date_created}_{original_name}{ext}"

        # 2-4. AI ê¸°ë°˜ í´ë” ë¶„ë¥˜
        if use_ai_classify and (ext in AI_SUPPORTED_EXTENSIONS or ext in AI_SUPPORTED_IMAGE_EXTENSIONS or ext in AI_SUPPORTED_AUDIO_EXTENSIONS):
            ai_folder = get_ai_folder_classification(old_path)
            if ai_folder and ai_folder != "ê¸°íƒ€":
                new_dir = target_path / ai_folder
        
        # 2-5. ê·œì¹™ ê¸°ë°˜ í´ë” ì´ë™ (AI ë¶„ë¥˜ê°€ ì ìš©ë˜ì§€ ì•Šì€ ê²½ìš°ë§Œ)
        elif not use_ai_classify:
            category = get_file_category(ext)
            if category != 'ê¸°íƒ€':
                new_dir = target_path / category
            else:
                new_dir = target_path / 'ê¸°íƒ€'

        new_path = new_dir / new_name

        if old_path != new_path:
            change_plan.append({'from': old_path, 'to': new_path})

    # 3. ê²°ê³¼ ì¶œë ¥ ë° ì‹¤í–‰
    if not change_plan:
        print("âœ… ëª¨ë“  íŒŒì¼ì´ ì´ë¯¸ ì •ë¦¬ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë³€ê²½í•  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    print("\nâœ¨ ë‹¤ìŒê³¼ ê°™ì´ íŒŒì¼ì´ ë³€ê²½ë  ì˜ˆì •ì…ë‹ˆë‹¤:\n")
    for change in change_plan:
        try:
            from_rel = change['from'].relative_to(Path.cwd())
            to_rel = change['to'].relative_to(Path.cwd())
            print(f"  - [ì´ë™/ë³€ê²½] '{from_rel}' -> '{to_rel}'")
        except ValueError:
            print(f"  - [ì´ë™/ë³€ê²½] '{change['from']}' -> '{change['to']}'")

    if dry_run:
        print("\nğŸ’§ Dry-run ëª¨ë“œì…ë‹ˆë‹¤. ì‹¤ì œ íŒŒì¼ì€ ë³€ê²½ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return

    # 4. ì‚¬ìš©ì í™•ì¸
    if not skip_confirm:
        confirm = input(f"\nì´ {len(change_plan)}ê°œì˜ íŒŒì¼ì„ ë³€ê²½í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ")
        if confirm.lower() != 'y':
            print("ì‘ì—…ì„ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤.")
            return

    # 5. ì‹¤ì œ íŒŒì¼ ë³€ê²½ ì‹¤í–‰
    print("\nğŸš€ íŒŒì¼ ì •ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    log_entries = []
    for change in change_plan:
        try:
            change['to'].parent.mkdir(parents=True, exist_ok=True)
            shutil.move(str(change['from']), str(change['to']))
            log_entry = f"[{datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] MOVED: '{change['from']}' -> '{change['to']}'"
            print(f"  - ì„±ê³µ: {change['from'].name} -> {change['to'].relative_to(target_path)}")
            log_entries.append(log_entry)
        except Exception as e:
            log_entry = f"[{datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] FAILED: '{change['from']}' -> '{change['to']}'. ì´ìœ : {e}"
            print(f"  - ì‹¤íŒ¨: {change['from'].name}. ì´ìœ : {e}")
            log_entries.append(log_entry)

    # 6. ë¡œê·¸ ê¸°ë¡
    if log_file:
        log_path = Path(log_file)
        with open(log_path, 'a', encoding='utf-8') as f:
            for entry in log_entries:
                f.write(entry + '\n')
        print(f"\nğŸ“ ì‘ì—… ê²°ê³¼ê°€ '{log_path.resolve()}' íŒŒì¼ì— ê¸°ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.")

    print("\nğŸ‰ íŒŒì¼ ì •ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")


def scan_files(target_path: Path, recursive: bool, by_ext: bool, by_date: bool):
    """í´ë” í˜„í™©ì„ ë¶„ì„í•˜ì—¬ ë¦¬í¬íŠ¸ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."""
    print(f"ğŸ“Š '{target_path.resolve()}' ê²½ë¡œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤...")
    
    files = []
    file_iterator = target_path.rglob('*') if recursive else target_path.glob('*')

    for item in file_iterator:
        if item.is_file():
            files.append(item)
    
    if not files:
        print("ë¶„ì„í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"\nì´ {len(files)}ê°œì˜ íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")

    if by_ext:
        print("\n--- í™•ì¥ìë³„ íŒŒì¼ í˜„í™© ---")
        ext_count = {}
        for file in files:
            ext = file.suffix.lower() or '.no_extension'
            ext_count[ext] = ext_count.get(ext, 0) + 1
        
        sorted_exts = sorted(ext_count.items(), key=lambda item: item[1], reverse=True)
        
        for ext, count in sorted_exts:
            print(f"  - {ext:<15}: {count}ê°œ")

    if by_date:
        print("\n--- ìˆ˜ì •ì¼ ê¸°ì¤€ íŒŒì¼ í˜„í™© (ê°€ì¥ ì˜¤ë˜ëœ íŒŒì¼ 5ê°œ) ---")
        files.sort(key=lambda f: f.stat().st_mtime)
        for file in files[:5]:
            mtime = datetime.datetime.fromtimestamp(file.stat().st_mtime).strftime('%Y-%m-%d %H:%M')
            print(f"  - [{mtime}] {file.name}")

# --- CLI ì¸í„°í˜ì´ìŠ¤ (CLI Interface) ---

def main():
    parser = argparse.ArgumentParser(
        prog="aifo",
        description="ğŸ¤– AI íŒŒì¼ ì •ë¦¬ ì—ì´ì „íŠ¸: AIì™€ ê·œì¹™ì„ ì‚¬ìš©í•˜ì—¬ íŒŒì¼ì„ ìë™ìœ¼ë¡œ ì •ë¦¬í•©ë‹ˆë‹¤.",
        epilog="ìì„¸í•œ ì‚¬ìš©ë²•ì€ 'aifo [COMMAND] --help'ë¥¼ ì…ë ¥í•˜ì„¸ìš”."
    )
    subparsers = parser.add_subparsers(dest="command", required=True, help="ìˆ˜í–‰í•  ì‘ì—…")

    # 'organize' ëª…ë ¹ì–´
    parser_organize = subparsers.add_parser("organize", help="ê·œì¹™ì— ë”°ë¼ íŒŒì¼ì„ ì •ë¦¬í•©ë‹ˆë‹¤.")
    parser_organize.add_argument("target_path", type=Path, help="ì •ë¦¬í•  í´ë” ê²½ë¡œ")
    parser_organize.add_argument("-m", "--model-path", type=str, default=DEFAULT_MODEL_PATH, 
                                help=f"AI ëª¨ë¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ (ê¸°ë³¸ê°’: {DEFAULT_MODEL_PATH})")
    parser_organize.add_argument("-d", "--dry-run", action="store_true", 
                                help="[ì•ˆì „ ê¸°ëŠ¥] ì‹¤ì œ íŒŒì¼ ë³€ê²½ ì—†ì´ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ë§Œ ë³´ì—¬ì¤ë‹ˆë‹¤.")
    parser_organize.add_argument("-r", "--recursive", action="store_true", 
                                help="í•˜ìœ„ í´ë”ë¥¼ í¬í•¨í•˜ì—¬ ì „ì²´ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤.")
    parser_organize.add_argument("-a", "--ai-keyword", action="store_true", 
                                help="[AI ê¸°ëŠ¥] ë¬¸ì„œ íŒŒì¼ ë‚´ìš© ê¸°ë°˜ìœ¼ë¡œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ì—¬ íŒŒì¼ëª…ì— ì¶”ê°€í•©ë‹ˆë‹¤.")
    parser_organize.add_argument("-f", "--ai-filename", action="store_true", 
                                help="[AI ê¸°ëŠ¥] ë¬¸ì„œ íŒŒì¼ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ì™„ì „íˆ ìƒˆë¡œìš´ íŒŒì¼ëª…ì„ ì œì•ˆí•©ë‹ˆë‹¤.")
    parser_organize.add_argument("-c", "--ai-classify", action="store_true", 
                                help="[AI ê¸°ëŠ¥] ë¬¸ì„œ íŒŒì¼ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ í´ë”ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤.")
    parser_organize.add_argument("-A", "--ai-all", action="store_true", 
                                help="[AI ê¸°ëŠ¥] ëª¨ë“  AI ê¸°ëŠ¥ì„ í™œì„±í™”í•©ë‹ˆë‹¤ (-a -f -c ì™€ ë™ì¼).")
    parser_organize.add_argument("-y", "--yes", action="store_true", 
                                help="[ì£¼ì˜] íŒŒì¼ ë³€ê²½ ì „ í™•ì¸ ì ˆì°¨ë¥¼ ìƒëµí•˜ê³  ì¦‰ì‹œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
    parser_organize.add_argument("-l", "--log", nargs='?', const=LOG_FILE_NAME, default=None, 
                                help=f"ì‘ì—… ë¡œê·¸ë¥¼ íŒŒì¼ë¡œ ê¸°ë¡í•©ë‹ˆë‹¤. íŒŒì¼ëª…ì„ ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ '{LOG_FILE_NAME}'ì— ì €ì¥ë©ë‹ˆë‹¤.")

    # 'scan' ëª…ë ¹ì–´
    parser_scan = subparsers.add_parser("scan", help="í´ë” í˜„í™©ì„ ë¶„ì„í•˜ì—¬ ë¦¬í¬íŠ¸ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.")
    parser_scan.add_argument("target_path", type=Path, help="ë¶„ì„í•  í´ë” ê²½ë¡œ")
    parser_scan.add_argument("-r", "--recursive", action="store_true", help="í•˜ìœ„ í´ë”ë¥¼ í¬í•¨í•˜ì—¬ ì „ì²´ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.")
    parser_scan.add_argument("-e", "--by-ext", action="store_true", help="í™•ì¥ìë³„ë¡œ íŒŒì¼ ê°œìˆ˜ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.")
    parser_scan.add_argument("-t", "--by-date", action="store_true", help="ìˆ˜ì •ì¼ ê¸°ì¤€ìœ¼ë¡œ íŒŒì¼ì„ ì •ë ¬í•˜ì—¬ ë³´ì—¬ì¤ë‹ˆë‹¤.")
    
    # 'config' ëª…ë ¹ì–´
    parser_config = subparsers.add_parser("config", help="ì„¤ì • ì •ë³´ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.")
    parser_config.add_argument("--show-categories", action="store_true", help="íŒŒì¼ ì¹´í…Œê³ ë¦¬ ì„¤ì •ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.")
    parser_config.add_argument("--show-ai-extensions", action="store_true", help="AI ì§€ì› í™•ì¥ìë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.")
    parser_config.add_argument("--show-model-path", action="store_true", help="í˜„ì¬ ëª¨ë¸ ê²½ë¡œë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.")

    args = parser.parse_args()

    # AI ëª¨ë“  ê¸°ëŠ¥ í™œì„±í™” ì²˜ë¦¬
    if hasattr(args, 'ai_all') and args.ai_all:
        args.ai_keyword = True
        args.ai_filename = True
        args.ai_classify = True

    # ëª…ë ¹ì–´ ì‹¤í–‰
    if args.command == "organize":
        if not args.target_path.is_dir():
            print(f"ì˜¤ë¥˜: '{args.target_path}'ëŠ” ìœ íš¨í•œ ë””ë ‰í† ë¦¬ê°€ ì•„ë‹™ë‹ˆë‹¤.")
            sys.exit(1)
        
        organize_files(
            args.target_path, args.model_path, args.dry_run, args.recursive, 
            args.ai_keyword, args.ai_filename, args.ai_classify,
            args.yes, args.log
        )
    
    elif args.command == "scan":
        if not args.target_path.is_dir():
            print(f"ì˜¤ë¥˜: '{args.target_path}'ëŠ” ìœ íš¨í•œ ë””ë ‰í† ë¦¬ê°€ ì•„ë‹™ë‹ˆë‹¤.")
            sys.exit(1)
        # scan ì—ì„œëŠ” by-extë‚˜ by-dateê°€ ì§€ì •ë˜ì§€ ì•Šìœ¼ë©´ ë‘˜ ë‹¤ ì‹¤í–‰
        run_all = not args.by_ext and not args.by_date
        scan_files(args.target_path, args.recursive, args.by_ext or run_all, args.by_date or run_all)
        
    elif args.command == "config":
        if args.show_categories:
            print("ğŸ“ íŒŒì¼ ì¹´í…Œê³ ë¦¬ ì„¤ì •:")
            for category, extensions in FILE_CATEGORIES.items():
                if category == 'ê¸°íƒ€':
                    print(f"  - {category}: ê¸°íƒ€ ëª¨ë“  íŒŒì¼")
                else:
                    print(f"  - {category}: {', '.join(extensions)}")
        
        elif args.show_ai_extensions:
            print("ğŸ§  AI ì§€ì› í™•ì¥ì:")
            print(f"  - í…ìŠ¤íŠ¸: {', '.join(AI_SUPPORTED_EXTENSIONS)}")
            print(f"  - ì´ë¯¸ì§€: {', '.join(AI_SUPPORTED_IMAGE_EXTENSIONS)}")
            print(f"  - ì˜¤ë””ì˜¤: {', '.join(AI_SUPPORTED_AUDIO_EXTENSIONS)}")
        
        elif args.show_model_path:
            print(f"ğŸ¤– ê¸°ë³¸ ëª¨ë¸ ê²½ë¡œ: {DEFAULT_MODEL_PATH}")
            model_path_obj = Path(DEFAULT_MODEL_PATH)
            if model_path_obj.exists():
                print("  âœ… ê²½ë¡œê°€ ì¡´ì¬í•©ë‹ˆë‹¤.")
            else:
                print("  âŒ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        
        else:
            # ê¸°ë³¸ì ìœ¼ë¡œ ëª¨ë“  ì„¤ì • ì •ë³´ í‘œì‹œ
            print("ğŸ“‹ AIFO ì„¤ì • ì •ë³´:")
            print(f"ğŸ¤– ê¸°ë³¸ ëª¨ë¸ ê²½ë¡œ: {DEFAULT_MODEL_PATH}")
            print(f"ğŸ§  AI ì§€ì› í™•ì¥ì - í…ìŠ¤íŠ¸: {', '.join(AI_SUPPORTED_EXTENSIONS)}")
            print(f"ğŸ§  AI ì§€ì› í™•ì¥ì - ì´ë¯¸ì§€: {', '.join(AI_SUPPORTED_IMAGE_EXTENSIONS)}")
            print(f"ğŸ§  AI ì§€ì› í™•ì¥ì - ì˜¤ë””ì˜¤: {', '.join(AI_SUPPORTED_AUDIO_EXTENSIONS)}")
            print(f"ğŸ“ íŒŒì¼ ì¹´í…Œê³ ë¦¬: {len(FILE_CATEGORIES)}ê°œ")
            print(f"ğŸš« ì œì™¸ íŒ¨í„´: {', '.join(EXCLUDE_PATTERNS)}")


if __name__ == "__main__":
    main()