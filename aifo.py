# aifo.py
# AI File Organizer CLI

import argparse
import datetime
import os
import shutil
import sys
from pathlib import Path
import yaml

# --- AI ëª¨ë“ˆ Import ---
# ai_module.pyê°€ ê°™ì€ í´ë”ì— ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
try:
    from ai_module import AIKeywordExtractor
except ImportError:
    print("ì˜¤ë¥˜: 'ai_module.py' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìŠ¤í¬ë¦½íŠ¸ì™€ ê°™ì€ í´ë”ì— ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
    sys.exit(1)

# --- ì„¤ì • (Configuration) ---

# ê·œì¹™ íŒŒì¼ì˜ ê¸°ë³¸ ì´ë¦„
RULES_FILE_NAME = "rules.yml"

# ë¡œê·¸ íŒŒì¼ì˜ ê¸°ë³¸ ì´ë¦„
LOG_FILE_NAME = "aifo.log"

# AI Extractor ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì „ì—­ìœ¼ë¡œ ê´€ë¦¬ (Lazy Loading)
AI_EXTRACTOR: AIKeywordExtractor | None = None

# --- AI ëª¨ë“ˆ ì—°ë™ í•¨ìˆ˜ ---

def initialize_ai_module(rules: dict) -> AIKeywordExtractor | None:
    """
    ê·œì¹™ íŒŒì¼ì— ëª…ì‹œëœ ëª¨ë¸ ê²½ë¡œë¥¼ ì‚¬ìš©í•˜ì—¬ AI ëª¨ë“ˆì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
    ì´ˆê¸°í™”ëŠ” í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì¤‘ í•œ ë²ˆë§Œ ìˆ˜í–‰ë©ë‹ˆë‹¤.
    """
    global AI_EXTRACTOR
    if AI_EXTRACTOR is not None:
        return AI_EXTRACTOR

    ai_settings = rules.get('ai_settings')
    if not ai_settings or not ai_settings.get('model_path'):
        print("ì˜¤ë¥˜: AI ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ 'rules.yml' íŒŒì¼ì— 'ai_settings'ì™€ 'model_path'ë¥¼ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.")
        print("ë„ì›€ë§: 'aifo config init'ìœ¼ë¡œ ì˜ˆì‹œ íŒŒì¼ì„ ìƒì„±í•˜ê³  ëª¨ë¸ ê²½ë¡œë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
        return None

    model_path = Path(ai_settings['model_path'])
    if not model_path.is_file():
        print(f"ì˜¤ë¥˜: ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”: {model_path}")
        return None

    print("ğŸ§  AI ëª¨ë¸ì„ ë¡œë”©í•©ë‹ˆë‹¤. ì ì‹œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...")
    try:
        AI_EXTRACTOR = AIKeywordExtractor(
            model_path=str(model_path),
            prompt_template=ai_settings.get('prompt_template')
        )
        print("âœ… AI ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
        return AI_EXTRACTOR
    except Exception as e:
        print(f"ì˜¤ë¥˜: AI ëª¨ë¸ ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ({e})")
        print("llama-cpp-python ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì¹˜ë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return None


def get_ai_keywords_from_file(file_path: Path) -> str:
    """
    ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ íŒŒì¼ì˜ ë‚´ìš©ì„ AI ëª¨ë“ˆì— ì „ë‹¬í•˜ì—¬ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ë°˜í™˜ë°›ìŠµë‹ˆë‹¤.
    """
    if AI_EXTRACTOR is None:
        # ì´ í•¨ìˆ˜ëŠ” AI ëª¨ë“ˆì´ ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ëœ í›„ì—ë§Œ í˜¸ì¶œë˜ì–´ì•¼ í•¨
        return "AI_ëª¨ë“ˆ_ì´ˆê¸°í™”_ì‹¤íŒ¨"

    print(f"ğŸ§  AI: '{file_path.name}' íŒŒì¼ ë‚´ìš© ë¶„ì„ ì¤‘...")
    try:
        content = file_path.read_text(encoding='utf-8', errors='ignore')
        if not content.strip():
            return "ë‚´ìš©ì—†ìŒ"
        
        keywords = AI_EXTRACTOR.extract_keywords(content, file_path.name)
        # íŒŒì¼ëª…ìœ¼ë¡œ ë¶€ì ì ˆí•œ ë¬¸ì ì œê±°
        safe_keywords = "".join(c for c in keywords if c.isalnum() or c in ['_', '-'])
        return safe_keywords if safe_keywords else "í‚¤ì›Œë“œì¶”ì¶œì‹¤íŒ¨"

    except Exception as e:
        print(f"ì˜¤ë¥˜: '{file_path.name}' íŒŒì¼ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return "í‚¤ì›Œë“œì¶”ì¶œì‹¤íŒ¨"

# --- ê·œì¹™ ê´€ë¦¬ (Rule Management) ---

def get_default_rules():
    """ê¸°ë³¸ ê·œì¹™ì„ ë‹´ì€ ë”•ì…”ë„ˆë¦¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    default_prompt = (
        "You are a file organization expert. Below is the content of a text file named '{file_name}'. "
        "Please read the content and extract the 3 most important keywords that best summarize this document. "
        "The keywords should be in Korean. Please provide the keywords as a single line, separated by underscores (_). "
        "For example: 'í”„ë¡œì íŠ¸_ê²°ê³¼ë³´ê³ ì„œ_2025'. Do not add any other explanation.\n\n"
        "File Content:\n---\n{file_content}\n---\nKeywords:"
    )
    return {
        'ai_settings': {
            'model_path': 'path/to/your/model.gguf',
            'prompt_template': default_prompt
        },
        'move': {
            'ë¬¸ì„œ': ['.pdf', '.docx', '.pptx', '.hwp', '.txt', '.md'],
            'ì´ë¯¸ì§€': ['.jpg', '.jpeg', '.png', '.gif'],
            'ë°ì´í„°': ['.csv', '.xlsx', '.json'],
            'ì••ì¶•íŒŒì¼': ['.zip', '.7z', '.rar'],
            'ê¸°íƒ€': 'others'
        },
        'rename': [
            {
                'target_ext': ['.txt', '.md'],
                'pattern': '{{date_created}}_{{original_name}}{{ext}}'
            },
            {
                'target_ext': ['.jpg', '.png'],
                'pattern': 'IMG_{{date_created}}_{{original_name}}{{ext}}'
            }
        ],
        'rename_ai': {
            'target_ext': ['.txt', '.md'],
            'pattern': '{{original_name}}_{{keywords}}{{ext}}'
        },
        'exclude': [
            '.git', '.DS_Store', 'node_modules', 'venv',
            RULES_FILE_NAME, LOG_FILE_NAME, 'ai_module.py', '__pycache__'
        ]
    }

def load_rules(rules_path: Path):
    """ì§€ì •ëœ ê²½ë¡œì—ì„œ rules.yml íŒŒì¼ì„ ì°¾ì•„ ë¡œë“œí•©ë‹ˆë‹¤. ì—†ìœ¼ë©´ ê¸°ë³¸ ê·œì¹™ì„ ì‚¬ìš©í•©ë‹ˆë‹¤."""
    if not rules_path.is_file():
        print(f"'{rules_path.name}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ê·œì¹™ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        return get_default_rules()

    try:
        with open(rules_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    except Exception as e:
        print(f"ì˜¤ë¥˜: '{rules_path.name}' íŒŒì¼ì„ ì½ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ({e})")
        sys.exit(1)

# --- í•µì‹¬ ë¡œì§ (Core Logic) ---

def organize_files(target_path: Path, rules: dict, dry_run: bool, recursive: bool, use_ai: bool, skip_confirm: bool, log_file: str | None):
    """íŒŒì¼ ì •ë¦¬ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""

    # AI ê¸°ëŠ¥ ì‚¬ìš© ì‹œ, ëª¨ë¸ ì´ˆê¸°í™”
    if use_ai:
        if not initialize_ai_module(rules):
            sys.exit(1) # ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œ í”„ë¡œê·¸ë¨ ì¢…ë£Œ

    # 1. ì •ë¦¬í•  íŒŒì¼ ëª©ë¡ ìŠ¤ìº”
    print(f"ğŸ” '{target_path.resolve()}' ê²½ë¡œë¥¼ ìŠ¤ìº”í•©ë‹ˆë‹¤...")
    files_to_organize = []
    file_iterator = target_path.rglob('*') if recursive else target_path.glob('*')

    exclude_list = rules.get('exclude', [])
    for item in file_iterator:
        if any(part in exclude_list for part in item.parts):
            continue
        if item.name in exclude_list:
            continue
        if item.is_file():
            files_to_organize.append(item)

    if not files_to_organize:
        print("ì •ë¦¬í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 2. ë³€ê²½ ê³„íš ìˆ˜ë¦½
    change_plan = []
    for old_path in files_to_organize:
        new_name = old_path.name
        new_dir = old_path.parent

        original_name = old_path.stem
        ext = old_path.suffix
        date_created = datetime.datetime.fromtimestamp(old_path.stat().st_ctime).strftime('%Y-%m-%d')

        # 2-1. ì´ë¦„ ë³€ê²½ ê³„íš (Rename)
        if use_ai and ext in rules.get('rename_ai', {}).get('target_ext', []):
            keywords = get_ai_keywords_from_file(old_path)
            pattern = rules['rename_ai'].get('pattern', '{{original_name}}_{{keywords}}{{ext}}')
            new_name = pattern.replace('{{original_name}}', original_name)\
                              .replace('{{keywords}}', keywords)\
                              .replace('{{ext}}', ext)
        else:
            for rule in rules.get('rename', []):
                if ext in rule.get('target_ext', []):
                    pattern = rule.get('pattern', '{{original_name}}{{ext}}')
                    new_name = pattern.replace('{{original_name}}', original_name)\
                                      .replace('{{date_created}}', date_created)\
                                      .replace('{{ext}}', ext)
                    break

        # 2-2. í´ë” ì´ë™ ê³„íš (Move)
        moved = False
        for dir_name, exts in rules.get('move', {}).items():
            if exts == 'others': continue
            if ext in exts:
                new_dir = target_path / dir_name
                moved = True
                break

        if not moved and 'others' in rules.get('move', {}):
            dir_name = rules['move']['others']
            if isinstance(dir_name, str):
                new_dir = target_path / dir_name

        new_path = new_dir / new_name

        if old_path != new_path:
            change_plan.append({'from': old_path, 'to': new_path})

    # 3. ê²°ê³¼ ì¶œë ¥ ë° ì‹¤í–‰
    if not change_plan:
        print("âœ… ëª¨ë“  íŒŒì¼ì´ ì´ë¯¸ ì •ë¦¬ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë³€ê²½í•  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    print("\nâœ¨ ë‹¤ìŒê³¼ ê°™ì´ íŒŒì¼ì´ ë³€ê²½ë  ì˜ˆì •ì…ë‹ˆë‹¤:\n")
    for change in change_plan:
        try:
            from_rel = change['from'].relative_to(Path.cwd())
            to_rel = change['to'].relative_to(Path.cwd())
            print(f"  - [ì´ë™/ë³€ê²½] '{from_rel}' -> '{to_rel}'")
        except ValueError:
            print(f"  - [ì´ë™/ë³€ê²½] '{change['from']}' -> '{change['to']}'")


    if dry_run:
        print("\nğŸ’§ Dry-run ëª¨ë“œì…ë‹ˆë‹¤. ì‹¤ì œ íŒŒì¼ì€ ë³€ê²½ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return

    # 4. ì‚¬ìš©ì í™•ì¸
    if not skip_confirm:
        confirm = input(f"\nì´ {len(change_plan)}ê°œì˜ íŒŒì¼ì„ ë³€ê²½í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ")
        if confirm.lower() != 'y':
            print("ì‘ì—…ì„ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤.")
            return

    # 5. ì‹¤ì œ íŒŒì¼ ë³€ê²½ ì‹¤í–‰
    print("\nğŸš€ íŒŒì¼ ì •ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    log_entries = []
    for change in change_plan:
        try:
            change['to'].parent.mkdir(parents=True, exist_ok=True)
            shutil.move(str(change['from']), str(change['to']))
            log_entry = f"[{datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] MOVED: '{change['from']}' -> '{change['to']}'"
            print(f"  - ì„±ê³µ: {change['from'].name} -> {change['to'].relative_to(target_path)}")
            log_entries.append(log_entry)
        except Exception as e:
            log_entry = f"[{datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] FAILED: '{change['from']}' -> '{change['to']}'. ì´ìœ : {e}"
            print(f"  - ì‹¤íŒ¨: {change['from'].name}. ì´ìœ : {e}")
            log_entries.append(log_entry)

    # 6. ë¡œê·¸ ê¸°ë¡
    if log_file:
        log_path = Path(log_file)
        with open(log_path, 'a', encoding='utf-8') as f:
            for entry in log_entries:
                f.write(entry + '\n')
        print(f"\nğŸ“ ì‘ì—… ê²°ê³¼ê°€ '{log_path.resolve()}' íŒŒì¼ì— ê¸°ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.")

    print("\nğŸ‰ íŒŒì¼ ì •ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")


def scan_files(target_path: Path, recursive: bool, by_ext: bool, by_date: bool):
    """í´ë” í˜„í™©ì„ ë¶„ì„í•˜ì—¬ ë¦¬í¬íŠ¸ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."""
    print(f"ğŸ“Š '{target_path.resolve()}' ê²½ë¡œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤...")
    
    files = []
    file_iterator = target_path.rglob('*') if recursive else target_path.glob('*')

    for item in file_iterator:
        if item.is_file():
            files.append(item)
    
    if not files:
        print("ë¶„ì„í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"\nì´ {len(files)}ê°œì˜ íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")

    if by_ext:
        print("\n--- í™•ì¥ìë³„ íŒŒì¼ í˜„í™© ---")
        ext_count = {}
        for file in files:
            ext = file.suffix.lower() or '.no_extension'
            ext_count[ext] = ext_count.get(ext, 0) + 1
        
        sorted_exts = sorted(ext_count.items(), key=lambda item: item[1], reverse=True)
        
        for ext, count in sorted_exts:
            print(f"  - {ext:<15}: {count}ê°œ")

    if by_date:
        print("\n--- ìˆ˜ì •ì¼ ê¸°ì¤€ íŒŒì¼ í˜„í™© (ê°€ì¥ ì˜¤ë˜ëœ íŒŒì¼ 5ê°œ) ---")
        files.sort(key=lambda f: f.stat().st_mtime)
        for file in files[:5]:
            mtime = datetime.datetime.fromtimestamp(file.stat().st_mtime).strftime('%Y-%m-%d %H:%M')
            print(f"  - [{mtime}] {file.name}")

# --- CLI ì¸í„°í˜ì´ìŠ¤ (CLI Interface) ---

def main():
    parser = argparse.ArgumentParser(
        prog="aifo",
        description="ğŸ¤– AI íŒŒì¼ ì •ë¦¬ ì—ì´ì „íŠ¸: ê·œì¹™ê³¼ AIë¥¼ ì‚¬ìš©í•˜ì—¬ íŒŒì¼ì„ ì •ë¦¬í•©ë‹ˆë‹¤.",
        epilog="ìì„¸í•œ ì‚¬ìš©ë²•ì€ 'aifo [COMMAND] --help'ë¥¼ ì…ë ¥í•˜ì„¸ìš”."
    )
    subparsers = parser.add_subparsers(dest="command", required=True, help="ìˆ˜í–‰í•  ì‘ì—…")

    # 'organize' ëª…ë ¹ì–´
    parser_organize = subparsers.add_parser("organize", help="ê·œì¹™ì— ë”°ë¼ íŒŒì¼ì„ ì •ë¦¬í•©ë‹ˆë‹¤.")
    parser_organize.add_argument("target_path", type=Path, help="ì •ë¦¬í•  í´ë” ê²½ë¡œ")
    parser_organize.add_argument("-R", "--rules", type=Path, default=Path(RULES_FILE_NAME), help=f"ì‚¬ìš©ì ì •ì˜ ê·œì¹™ íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: {RULES_FILE_NAME})")
    parser_organize.add_argument("-d", "--dry-run", action="store_true", help="[ì•ˆì „ ê¸°ëŠ¥] ì‹¤ì œ íŒŒì¼ ë³€ê²½ ì—†ì´ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ë§Œ ë³´ì—¬ì¤ë‹ˆë‹¤.")
    parser_organize.add_argument("-r", "--recursive", action="store_true", help="í•˜ìœ„ í´ë”ë¥¼ í¬í•¨í•˜ì—¬ ì „ì²´ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤.")
    parser_organize.add_argument("-a", "--ai-keyword", action="store_true", help="[AI ê¸°ëŠ¥] ë¬¸ì„œ íŒŒì¼ ë‚´ìš© ê¸°ë°˜ìœ¼ë¡œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ì—¬ íŒŒì¼ëª…ì— ì¶”ê°€í•©ë‹ˆë‹¤.")
    parser_organize.add_argument("-y", "--yes", action="store_true", help="[ì£¼ì˜] íŒŒì¼ ë³€ê²½ ì „ í™•ì¸ ì ˆì°¨ë¥¼ ìƒëµí•˜ê³  ì¦‰ì‹œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
    parser_organize.add_argument("-l", "--log", nargs='?', const=LOG_FILE_NAME, default=None, help=f"ì‘ì—… ë¡œê·¸ë¥¼ íŒŒì¼ë¡œ ê¸°ë¡í•©ë‹ˆë‹¤. íŒŒì¼ëª…ì„ ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ '{LOG_FILE_NAME}'ì— ì €ì¥ë©ë‹ˆë‹¤.")

    # 'scan' ëª…ë ¹ì–´
    parser_scan = subparsers.add_parser("scan", help="í´ë” í˜„í™©ì„ ë¶„ì„í•˜ì—¬ ë¦¬í¬íŠ¸ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.")
    parser_scan.add_argument("target_path", type=Path, help="ë¶„ì„í•  í´ë” ê²½ë¡œ")
    parser_scan.add_argument("-r", "--recursive", action="store_true", help="í•˜ìœ„ í´ë”ë¥¼ í¬í•¨í•˜ì—¬ ì „ì²´ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.")
    parser_scan.add_argument("-e", "--by-ext", action="store_true", help="í™•ì¥ìë³„ë¡œ íŒŒì¼ ê°œìˆ˜ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.")
    parser_scan.add_argument("-t", "--by-date", action="store_true", help="ìˆ˜ì •ì¼ ê¸°ì¤€ìœ¼ë¡œ íŒŒì¼ì„ ì •ë ¬í•˜ì—¬ ë³´ì—¬ì¤ë‹ˆë‹¤.")
    
    # 'config' ëª…ë ¹ì–´
    parser_config = subparsers.add_parser("config", help="ê·œì¹™ ì„¤ì • íŒŒì¼ì„ ê´€ë¦¬í•©ë‹ˆë‹¤.")
    config_subparsers = parser_config.add_subparsers(dest="config_command", required=True)
    config_subparsers.add_parser("init", help=f"í˜„ì¬ í´ë”ì— ì˜ˆì‹œ '{RULES_FILE_NAME}' íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.")
    config_subparsers.add_parser("show", help=f"í˜„ì¬ ì ìš©ë  '{RULES_FILE_NAME}' íŒŒì¼ì˜ ë‚´ìš©ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.")
    config_subparsers.add_parser("edit", help=f"ê¸°ë³¸ í¸ì§‘ê¸°ë¡œ '{RULES_FILE_NAME}' íŒŒì¼ì„ ì—½ë‹ˆë‹¤ (ê²½ë¡œ ì¶œë ¥).")

    args = parser.parse_args()

    # ëª…ë ¹ì–´ ì‹¤í–‰
    if args.command == "organize":
        if not args.target_path.is_dir():
            print(f"ì˜¤ë¥˜: '{args.target_path}'ëŠ” ìœ íš¨í•œ ë””ë ‰í† ë¦¬ê°€ ì•„ë‹™ë‹ˆë‹¤.")
            sys.exit(1)
        rules = load_rules(args.rules)
        organize_files(args.target_path, rules, args.dry_run, args.recursive, args.ai_keyword, args.yes, args.log)
    
    elif args.command == "scan":
        if not args.target_path.is_dir():
            print(f"ì˜¤ë¥˜: '{args.target_path}'ëŠ” ìœ íš¨í•œ ë””ë ‰í† ë¦¬ê°€ ì•„ë‹™ë‹ˆë‹¤.")
            sys.exit(1)
        # scan ì—ì„œëŠ” by-extë‚˜ by-dateê°€ ì§€ì •ë˜ì§€ ì•Šìœ¼ë©´ ë‘˜ ë‹¤ ì‹¤í–‰
        run_all = not args.by_ext and not args.by_date
        scan_files(args.target_path, args.recursive, args.by_ext or run_all, args.by_date or run_all)
        
    elif args.command == "config":
        rules_path = Path(RULES_FILE_NAME)
        if args.config_command == "init":
            if rules_path.exists():
                overwrite = input(f"'{rules_path}' íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. ë®ì–´ì“°ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").lower()
                if overwrite != 'y':
                    print("ì‘ì—…ì„ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤.")
                    return
            
            with open(rules_path, 'w', encoding='utf-8') as f:
                yaml.dump(get_default_rules(), f, allow_unicode=True, sort_keys=False, indent=2)
            print(f"âœ… ì˜ˆì‹œ ê·œì¹™ íŒŒì¼ '{rules_path.resolve()}'ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤. model_pathë¥¼ ìˆ˜ì •í•´ì£¼ì„¸ìš”.")
        
        elif args.config_command == "show":
            if not rules_path.exists():
                print(f"'{rules_path}' íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. 'aifo config init' ëª…ë ¹ì–´ë¡œ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            else:
                print(f"--- {rules_path.resolve()} ë‚´ìš© ---")
                print(rules_path.read_text(encoding='utf-8'))
                
        elif args.config_command == "edit":
            print(f"ì•„ë˜ ê²½ë¡œì˜ íŒŒì¼ì„ ì§ì ‘ ì—´ì–´ì„œ ìˆ˜ì •í•´ì£¼ì„¸ìš”:\n{rules_path.resolve()}")


if __name__ == "__main__":
    main()
