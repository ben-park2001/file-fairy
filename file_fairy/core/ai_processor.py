import re
import onnxruntime
import numpy as np
from transformers import AutoConfig, AutoProcessor
from pathlib import Path
from typing import Optional


class AIKeywordExtractor:
    """
    Gemma ONNX ëª¨ë¸ì„ ì‚¬ìš©í•œ AI í‚¤ì›Œë“œ ì¶”ì¶œ ë° íŒŒì¼ ë¶„ë¥˜ í´ë˜ìŠ¤
    """
    
    def __init__(self, model_path: str, prompt_template: Optional[str] = None):
        """
        AI ëª¨ë¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
        
        Args:
            model_path: ONNX ëª¨ë¸ë“¤ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ
            prompt_template: ì‚¬ìš©ì ì •ì˜ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        """
        self.model_dir = Path(model_path)
        self.prompt_template = prompt_template or self._get_default_prompt_template()
        
        # ëª¨ë¸ ê´€ë ¨ ë³€ìˆ˜ë“¤
        self.processor = None
        self.config = None
        self.embed_session = None
        self.decoder_session = None
        self.vision_session = None
        self.audio_session = None
        self.eos_token_id = 106
        self.image_token_id = None
        self.audio_token_id = None
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        self._load_models()
    
    def _get_default_prompt_template(self) -> str:
        """ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return """You are an expert file naming and classification specialist. Analyze the original filename and file content to generate optimal results.

Original filename: {file_name}
File content:
---
{file_content}
---

TASK: 
1. Evaluate if the original filename accurately represents the file content
2. Generate a new descriptive filename (3-8 words, use underscores, include extension)
3. Suggest an appropriate folder name in Korean

GUIDELINES:
- If original filename is descriptive and accurate, use it as reference for the new filename
- If original filename is generic or unclear, create a completely new descriptive filename
- New filename should be concise but comprehensive
- Use clear, common terminology
- Folder name should be in Korean and categorize the file appropriately

EXAMPLES:
Original: document1.pdf, Content: quarterly sales report Q3 2024
â†’ í‚¤ì›Œë“œ: Q3_2024_quarterly_sales_report.pdf
â†’ í´ë”: ë§¤ì¶œë³´ê³ ì„œ

Original: notes.txt, Content: project meeting discussing timeline and budget
â†’ í‚¤ì›Œë“œ: project_meeting_timeline_budget.txt  
â†’ í´ë”: íšŒì˜ë¡

OUTPUT FORMAT:
í‚¤ì›Œë“œ: [new_filename_with_extension]
í´ë”: [Korean_folder_name]"""

    def _load_models(self):
        """ONNX ëª¨ë¸ë“¤ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
        try:
            print("ğŸ”„ Processorì™€ Config ë¡œë”© ì¤‘...")
            
            # ì²« ë²ˆì§¸ ì‹œë„: ë¡œì»¬ íŒŒì¼ë§Œ ì‚¬ìš©
            try:
                self.processor = AutoProcessor.from_pretrained(
                    str(self.model_dir),
                    local_files_only=True
                )
                self.config = AutoConfig.from_pretrained(
                    str(self.model_dir),
                    local_files_only=True
                )
                print("âœ… ë¡œì»¬ íŒŒì¼ë¡œ Config/Processor ë¡œë“œ ì„±ê³µ")
            except Exception as local_e:
                print(f"âš ï¸  ë¡œì»¬ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨, ì˜¨ë¼ì¸ fallback ì‹œë„: {local_e}")
                # Fallback: ì˜¨ë¼ì¸ì—ì„œ ë¡œë“œ
                model_id = "google/gemma-3n-E2B-it"
                self.processor = AutoProcessor.from_pretrained(model_id)
                self.config = AutoConfig.from_pretrained(model_id)
                print("âœ… ì˜¨ë¼ì¸ìœ¼ë¡œ Config/Processor ë¡œë“œ ì„±ê³µ")
            
            # ONNX ëª¨ë¸ ê²½ë¡œë“¤
            embed_model_path = self.model_dir / "onnx/embed_tokens_quantized.onnx"
            decoder_model_path = self.model_dir / "onnx/decoder_model_merged_q4.onnx"
            vision_model_path = self.model_dir / "onnx/vision_encoder_quantized.onnx"
            audio_model_path = self.model_dir / "onnx/audio_encoder_quantized.onnx"
            
            print(f"ğŸ” ëª¨ë¸ íŒŒì¼ ê²½ë¡œ í™•ì¸:")
            print(f"   Embed: {embed_model_path} (ì¡´ì¬: {embed_model_path.exists()})")
            print(f"   Decoder: {decoder_model_path} (ì¡´ì¬: {decoder_model_path.exists()})")
            print(f"   Vision: {vision_model_path} (ì¡´ì¬: {vision_model_path.exists()})")
            print(f"   Audio: {audio_model_path} (ì¡´ì¬: {audio_model_path.exists()})")
            
            # ëª¨ë¸ íŒŒì¼ ì¡´ì¬ í™•ì¸
            if not embed_model_path.exists():
                raise FileNotFoundError(f"Embed model not found: {embed_model_path}")
            if not decoder_model_path.exists():
                raise FileNotFoundError(f"Decoder model not found: {decoder_model_path}")
            if not vision_model_path.exists():
                print(f"âš ï¸  Vision model not found: {vision_model_path}")
                print("    Vision ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
                self.vision_session = None
            if not audio_model_path.exists():
                print(f"âš ï¸  Audio model not found: {audio_model_path}")
                print("    Audio ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
                self.audio_session = None
            
            # Provider ì„¤ì • (CUDA ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸)
            available_providers = onnxruntime.get_available_providers()
            print(f"ğŸ”§ ì‚¬ìš© ê°€ëŠ¥í•œ providers: {available_providers}")
            
            if 'CUDAExecutionProvider' in available_providers:
                providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']
                print("âœ… CUDA Provider ì‚¬ìš© ê°€ëŠ¥")
            else:
                providers = ['CPUExecutionProvider']
                print("âš ï¸  CUDA ì‚¬ìš© ë¶ˆê°€, CPUë§Œ ì‚¬ìš©")
                
            providers= ['CUDAExecutionProvider', 'CPUExecutionProvider']
            
            # ONNX ì„¸ì…˜ ìƒì„±
            print("ğŸ”„ ONNX ì„¸ì…˜ ìƒì„± ì¤‘...")
            
            # Embed ëª¨ë¸
            try:
                self.embed_session = onnxruntime.InferenceSession(str(embed_model_path), providers=providers)
                embed_provider = self.embed_session.get_providers()[0]
                print(f"âœ… Embed model using: {embed_provider}")
            except Exception as e:
                raise RuntimeError(f"Embed model ë¡œë“œ ì‹¤íŒ¨: {e}")
            
            # Decoder ëª¨ë¸  
            try:
                self.decoder_session = onnxruntime.InferenceSession(str(decoder_model_path), providers=providers)
                decoder_provider = self.decoder_session.get_providers()[0]
                print(f"âœ… Decoder model using: {decoder_provider}")
            except Exception as e:
                raise RuntimeError(f"Decoder model ë¡œë“œ ì‹¤íŒ¨: {e}")
            
            # Vision ëª¨ë¸ (ì„ íƒì )
            if vision_model_path.exists():
                try:
                    self.vision_session = onnxruntime.InferenceSession(str(vision_model_path), providers=providers)
                    vision_provider = self.vision_session.get_providers()[0]
                    print(f"âœ… Vision model using: {vision_provider}")
                    
                    # Vision ëª¨ë¸ì˜ ì…ë ¥/ì¶œë ¥ ì •ë³´ í™•ì¸
                    print(f"ğŸ” Vision model ì…ë ¥ ì •ë³´:")
                    for input_meta in self.vision_session.get_inputs():
                        print(f"   ì´ë¦„: {input_meta.name}, íƒ€ì…: {input_meta.type}, í˜•íƒœ: {input_meta.shape}")
                    
                    print(f"ğŸ” Vision model ì¶œë ¥ ì •ë³´:")
                    for output_meta in self.vision_session.get_outputs():
                        print(f"   ì´ë¦„: {output_meta.name}, íƒ€ì…: {output_meta.type}, í˜•íƒœ: {output_meta.shape}")
                        
                except Exception as e:
                    print(f"âš ï¸  Vision model ë¡œë“œ ì‹¤íŒ¨: {e}")
                    print("    í…ìŠ¤íŠ¸ ì „ìš© ëª¨ë“œë¡œ ì‘ë™í•©ë‹ˆë‹¤.")
                    self.vision_session = None
            
            # Audio ëª¨ë¸ (ì„ íƒì )
            if audio_model_path.exists():
                try:
                    self.audio_session = onnxruntime.InferenceSession(str(audio_model_path), providers=providers)
                    audio_provider = self.audio_session.get_providers()[0]
                    print(f"âœ… Audio model using: {audio_provider}")
                    
                    # Audio ëª¨ë¸ì˜ ì…ë ¥/ì¶œë ¥ ì •ë³´ í™•ì¸
                    print(f"ğŸ” Audio model ì…ë ¥ ì •ë³´:")
                    for input_meta in self.audio_session.get_inputs():
                        print(f"   ì´ë¦„: {input_meta.name}, íƒ€ì…: {input_meta.type}, í˜•íƒœ: {input_meta.shape}")
                    
                    print(f"ğŸ” Audio model ì¶œë ¥ ì •ë³´:")
                    for output_meta in self.audio_session.get_outputs():
                        print(f"   ì´ë¦„: {output_meta.name}, íƒ€ì…: {output_meta.type}, í˜•íƒœ: {output_meta.shape}")
                        
                except Exception as e:
                    print(f"âš ï¸  Audio model ë¡œë“œ ì‹¤íŒ¨: {e}")
                    print("    ì˜¤ë””ì˜¤ ì²˜ë¦¬ ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
                    self.audio_session = None
            
            # ì„¤ì •ê°’ë“¤
            self.num_key_value_heads = self.config.text_config.num_key_value_heads
            self.head_dim = self.config.text_config.head_dim
            self.num_hidden_layers = self.config.text_config.num_hidden_layers
            self.image_token_id = getattr(self.config, 'image_token_id', 262145)
            self.audio_token_id = getattr(self.config, 'audio_token_id', None)
            
            print(f"ğŸ”§ Config ê°’ë“¤:")
            print(f"   Key-Value heads: {self.num_key_value_heads}")
            print(f"   Head dimension: {self.head_dim}")
            print(f"   Hidden layers: {self.num_hidden_layers}")
            print(f"   Image token ID: {self.image_token_id}")
            print(f"   Audio token ID: {self.audio_token_id}")
            
            print("âœ… Gemma ONNX ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨ ìƒì„¸ ì •ë³´:")
            print(f"   ì˜¤ë¥˜: {e}")
            print(f"   íƒ€ì…: {type(e).__name__}")
            import traceback
            traceback.print_exc()
            raise RuntimeError(f"ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
    
    def _generate_response(self, prompt: str, max_new_tokens: int = 64, image_path: Optional[str] = None, audio_path: Optional[str] = None) -> str:
        """
        ì£¼ì–´ì§„ í”„ë¡¬í”„íŠ¸ì— ëŒ€í•´ AI ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            prompt: ì…ë ¥ í”„ë¡¬í”„íŠ¸
            max_new_tokens: ìµœëŒ€ ìƒì„± í† í° ìˆ˜
            image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ (ì„ íƒì‚¬í•­)
            audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ (ì„ íƒì‚¬í•­)
            
        Returns:
            ìƒì„±ëœ ì‘ë‹µ í…ìŠ¤íŠ¸
        """
        try:
            # ë©”ì‹œì§€ í˜•íƒœë¡œ ë³€í™˜
            content = [{"type": "text", "text": prompt}]
            if image_path and Path(image_path).exists():
                content.append({"type": "image", "image": str(image_path)})
            if audio_path and Path(audio_path).exists():
                content.append({"type": "audio", "audio": str(audio_path)})
            
            messages = [{"role": "user", "content": content}]
            
            # í† í¬ë‚˜ì´ì €ë¡œ ì…ë ¥ ì²˜ë¦¬
            inputs = self.processor.apply_chat_template(
                messages,
                add_generation_prompt=True,
                tokenize=True,
                return_dict=True,
                return_tensors="pt",
            )
            
            input_ids = inputs["input_ids"].numpy().astype(np.int64)
            attention_mask = inputs["attention_mask"].numpy().astype(np.int64)
            position_ids = np.cumsum(attention_mask, axis=-1) - 1
            
            # ì´ë¯¸ì§€ ë°ì´í„° ì²˜ë¦¬
            pixel_values = inputs.get("pixel_values")
            if pixel_values is not None:
                pixel_values = pixel_values.numpy()
            
            # ì˜¤ë””ì˜¤ ë°ì´í„° ì²˜ë¦¬
            input_features = inputs.get("input_features")
            input_features_mask = inputs.get("input_features_mask")
            if input_features is not None:
                input_features = input_features.numpy().astype(np.float32)
            if input_features_mask is not None:
                input_features_mask = input_features_mask.numpy()
            
            # KV ìºì‹œ ì´ˆê¸°í™”
            batch_size = input_ids.shape[0]
            past_key_values = {
                f"past_key_values.{layer}.{kv}": np.zeros([batch_size, self.num_key_value_heads, 0, self.head_dim], dtype=np.float32)
                for layer in range(self.num_hidden_layers)
                for kv in ("key", "value")
            }
            
            # ìƒì„± ë£¨í”„
            generated_tokens = np.array([[]], dtype=np.int64)
            image_features = None
            audio_features = None
            
            for i in range(max_new_tokens):
                # ì„ë² ë”© ìƒì„±
                inputs_embeds, per_layer_inputs = self.embed_session.run(None, {"input_ids": input_ids})
                
                # ì´ë¯¸ì§€ ì²˜ë¦¬ (ì²« ë²ˆì§¸ ë°˜ë³µì—ì„œë§Œ)
                if image_features is None and pixel_values is not None and self.vision_session is not None and self.image_token_id is not None:
                    image_features = self.vision_session.run(
                        ["image_features"],
                        {"pixel_values": pixel_values}
                    )[0]
                    
                    # ì´ë¯¸ì§€ í† í°ì„ ì´ë¯¸ì§€ íŠ¹ì§•ìœ¼ë¡œ êµì²´
                    mask = (input_ids == self.image_token_id).reshape(-1)
                    flat_embeds = inputs_embeds.reshape(-1, inputs_embeds.shape[-1])
                    flat_embeds[mask] = image_features.reshape(-1, image_features.shape[-1])
                    inputs_embeds = flat_embeds.reshape(inputs_embeds.shape)
                
                # ì˜¤ë””ì˜¤ ì²˜ë¦¬ (ì²« ë²ˆì§¸ ë°˜ë³µì—ì„œë§Œ)
                if audio_features is None and input_features is not None and input_features_mask is not None and self.audio_session is not None and self.audio_token_id is not None:
                    audio_features = self.audio_session.run(
                        ["audio_features"],
                        {
                            "input_features": input_features,
                            "input_features_mask": input_features_mask,
                        }
                    )[0]
                    
                    # ì˜¤ë””ì˜¤ í† í°ì„ ì˜¤ë””ì˜¤ íŠ¹ì§•ìœ¼ë¡œ êµì²´
                    mask = (input_ids == self.audio_token_id).reshape(-1)
                    flat_embeds = inputs_embeds.reshape(-1, inputs_embeds.shape[-1])
                    flat_embeds[mask] = audio_features.reshape(-1, audio_features.shape[-1])
                    inputs_embeds = flat_embeds.reshape(inputs_embeds.shape)
                
                # ë””ì½”ë” ì‹¤í–‰
                logits, *present_key_values = self.decoder_session.run(None, dict(
                    inputs_embeds=inputs_embeds,
                    per_layer_inputs=per_layer_inputs,
                    position_ids=position_ids,
                    **past_key_values,
                ))
                
                # ë‹¤ìŒ í† í° ì„ íƒ
                input_ids = logits[:, -1].argmax(-1, keepdims=True)
                attention_mask = np.ones_like(input_ids)
                position_ids = position_ids[:, -1:] + 1
                
                # KV ìºì‹œ ì—…ë°ì´íŠ¸
                for j, key in enumerate(past_key_values):
                    past_key_values[key] = present_key_values[j]
                
                generated_tokens = np.concatenate([generated_tokens, input_ids], axis=-1)
                
                # EOS í† í° í™•ì¸
                if (input_ids == self.eos_token_id).all():
                    break
            
            # ê²°ê³¼ ë””ì½”ë”©
            response = self.processor.batch_decode(generated_tokens, skip_special_tokens=True)[0]
            return response.strip()
            
        except Exception as e:
            print(f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            return "ì‘ë‹µ_ìƒì„±_ì‹¤íŒ¨"
    
    def process_file_content(self, file_name: str, file_content: str) -> str:
        """
        Process file content to get AI suggestions for naming and categorization.
        
        Args:
            file_name: Original filename
            file_content: File content to analyze
            
        Returns:
            AI response with keywords and folder suggestions
        """
        try:
            # Use the default prompt template to get structured response
            prompt = self.prompt_template.format(
                file_name=file_name,
                file_content=file_content[:2000]  # Limit content length
            )
            
            return self.generate_response(prompt)
            
        except Exception as e:
            print(f"íŒŒì¼ ë‚´ìš© ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            return "í‚¤ì›Œë“œ: ë¶„ì„ì‹¤íŒ¨\ní´ë”: ê¸°íƒ€"
    
    def extract_keywords(self, file_content: str, file_name: str, image_path: Optional[str] = None, audio_path: Optional[str] = None) -> str:
        """
        íŒŒì¼ ë‚´ìš©ìœ¼ë¡œë¶€í„° í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
        
        Args:
            file_content: íŒŒì¼ ë‚´ìš©
            file_name: íŒŒì¼ëª…
            image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ (ì„ íƒì‚¬í•­)
            audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ (ì„ íƒì‚¬í•­)
            
        Returns:
            ì¶”ì¶œëœ í‚¤ì›Œë“œ (ë°‘ì¤„ë¡œ ì—°ê²°ëœ í˜•íƒœ)
        """
        try:
            # íŒŒì¼ ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸° (í† í° ì œí•œ)
            if len(file_content) > 2000:
                file_content = file_content[:2000] + "..."
            
            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            if image_path or audio_path:
                content_desc = []
                if image_path:
                    content_desc.append("ì´ë¯¸ì§€")
                if audio_path:
                    content_desc.append("ì˜¤ë””ì˜¤")
                content_type = "ì™€ ".join(content_desc)
                
                if file_content.strip():
                    prompt = f"""{content_type}ì™€ í…ìŠ¤íŠ¸ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒì„ ì œê³µí•´ì£¼ì„¸ìš”:

Original filename: {file_name}
í…ìŠ¤íŠ¸ ë‚´ìš©:
---
{file_content}
---

ìš”ì²­ì‚¬í•­:
1. {content_type}ì™€ í…ìŠ¤íŠ¸ ë‚´ìš©ì„ ì¢…í•©í•˜ì—¬ ìš”ì•½í•˜ëŠ” í•œêµ­ì–´ í‚¤ì›Œë“œ 3ê°œ (ë°‘ì¤„ë¡œ ì—°ê²°: ì˜ˆì‹œ_í‚¤ì›Œë“œ_í˜•íƒœ)

ì‘ë‹µ í˜•ì‹:
í‚¤ì›Œë“œ: [í‚¤ì›Œë“œ1_í‚¤ì›Œë“œ2_í‚¤ì›Œë“œ3]"""
                else:
                    prompt = f"""{content_type}ë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒì„ ì œê³µí•´ì£¼ì„¸ìš”:

Original filename: {file_name}

ìš”ì²­ì‚¬í•­:
1. {content_type}ì˜ ë‚´ìš©ì„ ìš”ì•½í•˜ëŠ” í•œêµ­ì–´ í‚¤ì›Œë“œ 3ê°œ (ë°‘ì¤„ë¡œ ì—°ê²°: ì˜ˆì‹œ_í‚¤ì›Œë“œ_í˜•íƒœ)
2. êµ¬ì²´ì ì´ê³  ì˜ë¯¸ìˆëŠ” í‚¤ì›Œë“œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”

ì‘ë‹µ í˜•ì‹:
í‚¤ì›Œë“œ: [í‚¤ì›Œë“œ1_í‚¤ì›Œë“œ2_í‚¤ì›Œë“œ3]"""
            else:
                prompt = self.prompt_template.format(
                    file_content=file_content,
                    file_name=file_name
                )
            
            # AI ì‘ë‹µ ìƒì„±
            response = self._generate_response(prompt, image_path=image_path, audio_path=audio_path)
            
            # ëª¨ë¸ì´ ì—†ê³  ë¯¸ë””ì–´ë§Œ ìˆëŠ” ê²½ìš° ê¸°ë³¸ í‚¤ì›Œë“œ ë°˜í™˜
            if image_path and not self.vision_session and not file_content.strip():
                return "ì´ë¯¸ì§€_ë¶„ì„ë¶ˆê°€_ë¹„ì „ëª¨ë¸ì—†ìŒ"
            if audio_path and not self.audio_session and not file_content.strip():
                return "ì˜¤ë””ì˜¤_ë¶„ì„ë¶ˆê°€_ì˜¤ë””ì˜¤ëª¨ë¸ì—†ìŒ"
            
            # í‚¤ì›Œë“œ ì¶”ì¶œ
            keywords = self._parse_keywords_from_response(response)
            return keywords
            
        except Exception as e:
            print(f"í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
            return "í‚¤ì›Œë“œì¶”ì¶œì‹¤íŒ¨"
    
    def classify_folder(self, file_content: str, file_name: str, image_path: Optional[str] = None, audio_path: Optional[str] = None) -> str:
        """
        íŒŒì¼ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ í´ë”ëª…ì„ ì œì•ˆí•©ë‹ˆë‹¤.
        
        Args:
            file_content: íŒŒì¼ ë‚´ìš©
            file_name: íŒŒì¼ëª…
            image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ (ì„ íƒì‚¬í•­)
            audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ (ì„ íƒì‚¬í•­)
            
        Returns:
            ì œì•ˆëœ í´ë”ëª…
        """
        try:
            # íŒŒì¼ ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸°
            if len(file_content) > 2000:
                file_content = file_content[:2000] + "..."
            
            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            if image_path or audio_path:
                content_desc = []
                if image_path:
                    content_desc.append("ì´ë¯¸ì§€")
                if audio_path:
                    content_desc.append("ì˜¤ë””ì˜¤")
                content_type = "ì™€ ".join(content_desc)
                
                if file_content.strip():
                    prompt = f"""{content_type}ì™€ í…ìŠ¤íŠ¸ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒì„ ì œê³µí•´ì£¼ì„¸ìš”:

í…ìŠ¤íŠ¸ ë‚´ìš©:
---
{file_content}
---

ìš”ì²­ì‚¬í•­:
1. {content_type}ì™€ í…ìŠ¤íŠ¸ ë‚´ìš©ì„ ì¢…í•©í•˜ì—¬ ì´ íŒŒì¼ì´ ì†í•  ì ì ˆí•œ í´ë”ëª… 1ê°œ (í•œêµ­ì–´)

ì‘ë‹µ í˜•ì‹:
í´ë”: [í´ë”ëª…]"""
                else:
                    prompt = f"""{content_type}ë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒì„ ì œê³µí•´ì£¼ì„¸ìš”:

ìš”ì²­ì‚¬í•­:
1. {content_type}ì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì´ íŒŒì¼ì´ ì†í•  ì ì ˆí•œ í´ë”ëª… 1ê°œ (í•œêµ­ì–´)
2. êµ¬ì²´ì ì´ê³  ì˜ë¯¸ìˆëŠ” í´ë”ëª…ì„ ì œì•ˆí•´ì£¼ì„¸ìš”

ì‘ë‹µ í˜•ì‹:
í´ë”: [í´ë”ëª…]"""
            else:
                prompt = self.prompt_template.format(
                    file_content=file_content,
                    file_name=file_name
                )
            
            # AI ì‘ë‹µ ìƒì„±
            response = self._generate_response(prompt, image_path=image_path, audio_path=audio_path)
            
            # ëª¨ë¸ì´ ì—†ê³  ë¯¸ë””ì–´ë§Œ ìˆëŠ” ê²½ìš° ê¸°ë³¸ í´ë”ëª… ë°˜í™˜
            if image_path and not self.vision_session and not file_content.strip():
                return "ì´ë¯¸ì§€"
            if audio_path and not self.audio_session and not file_content.strip():
                return "ì˜¤ë””ì˜¤"
            
            # í´ë”ëª… ì¶”ì¶œ
            folder_name = self._parse_folder_from_response(response)
            return folder_name
            
        except Exception as e:
            print(f"í´ë” ë¶„ë¥˜ ì¤‘ ì˜¤ë¥˜: {e}")
            return "ê¸°íƒ€"
    
    def suggest_filename(self, file_content: str, original_name: str, extension: str, image_path: Optional[str] = None, audio_path: Optional[str] = None) -> str:
        """
        íŒŒì¼ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ íŒŒì¼ëª…ì„ ì œì•ˆí•©ë‹ˆë‹¤.
        
        Args:
            file_content: íŒŒì¼ ë‚´ìš©
            original_name: ì›ë³¸ íŒŒì¼ëª… (í™•ì¥ì ì œì™¸)
            extension: íŒŒì¼ í™•ì¥ì
            image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ (ì„ íƒì‚¬í•­)
            audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ (ì„ íƒì‚¬í•­)
            
        Returns:
            ì œì•ˆëœ íŒŒì¼ëª… (í™•ì¥ì í¬í•¨)
        """
        try:
            # íŒŒì¼ ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸° (í† í° ì œí•œ)
            if len(file_content) > 2000:
                file_content = file_content[:2000] + "..."
            
            original_filename = original_name + extension
            
            # í”„ë¡¬í”„íŠ¸ ìƒì„± - ê¸°ì¡´ ì œëª©ê³¼ ë‚´ìš©ì„ í•¨ê»˜ ë¶„ì„
            if image_path or audio_path:
                content_desc = []
                if image_path:
                    content_desc.append("ì´ë¯¸ì§€")
                if audio_path:
                    content_desc.append("ì˜¤ë””ì˜¤")
                content_type = "ì™€ ".join(content_desc)
                
                if file_content.strip():
                    prompt = f"""You are an expert file naming specialist for multimedia files. Analyze the original filename and content to generate an optimal new filename.

Original filename: {original_filename}
Content type: {content_type}
Text content:
---
{file_content}
---

TASK: Generate a new descriptive filename that represents both the {content_type} and text content.

GUIDELINES:
- 3-8 words maximum, use underscores
- Include original extension: {extension}
- If original filename is descriptive, reference it
- If original filename is generic (like IMG_001 or audio_file), create a completely new name
- Be specific and descriptive

OUTPUT FORMAT:
í‚¤ì›Œë“œ: [new_filename{extension}]"""
                else:
                    prompt = f"""You are an expert file naming specialist. Analyze the original filename and {content_type} to generate an optimal new filename.

Original filename: {original_filename}
Content type: {content_type}

TASK: Generate a new descriptive filename for this {content_type} file.

GUIDELINES:
- 3-8 words maximum, use underscores
- Include original extension: {extension}
- If original filename is descriptive, reference it
- If original filename is generic, create a completely new descriptive name

OUTPUT FORMAT:
í‚¤ì›Œë“œ: [new_filename{extension}]"""
            else:
                # í…ìŠ¤íŠ¸ íŒŒì¼ì˜ ê²½ìš° ê¸°ë³¸ í…œí”Œë¦¿ ì‚¬ìš©
                prompt = self.prompt_template.format(
                    file_content=file_content,
                    file_name=original_filename
                )
            
            # AI ì‘ë‹µ ìƒì„±
            response = self._generate_response(prompt, image_path=image_path, audio_path=audio_path)
            
            # ëª¨ë¸ì´ ì—†ê³  ë¯¸ë””ì–´ë§Œ ìˆëŠ” ê²½ìš° ê¸°ë³¸ íŒŒì¼ëª… ë°˜í™˜
            if image_path and not self.vision_session and not file_content.strip():
                return f"image_content{extension}"
            if audio_path and not self.audio_session and not file_content.strip():
                return f"audio_content{extension}"
            
            # ìƒˆë¡œìš´ íŒŒì¼ëª… ì¶”ì¶œ
            new_filename = self._parse_keywords_from_response(response)
            
            # í™•ì¥ìê°€ ì—†ë‹¤ë©´ ì¶”ê°€
            if not new_filename.endswith(extension):
                # í‚¤ì›Œë“œì—ì„œ í™•ì¥ì ì œê±° í›„ ì˜¬ë°”ë¥¸ í™•ì¥ì ì¶”ê°€
                if '.' in new_filename:
                    new_filename = new_filename.rsplit('.', 1)[0]
                new_filename += extension
            
            # íŒŒì¼ëª…ìœ¼ë¡œ ì í•©í•˜ì§€ ì•Šì€ ë¬¸ì ì œê±°
            safe_filename = re.sub(r'[<>:"/\\|?*]', '_', new_filename)
            safe_filename = re.sub(r'_+', '_', safe_filename).strip('_')
            
            # íŒŒì¼ëª…ì´ ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸°
            name_part = safe_filename.replace(extension, '')
            if len(name_part) > 50:
                name_part = name_part[:50].rstrip('_')
                safe_filename = name_part + extension
            
            # ìƒì„±ì— ì‹¤íŒ¨í–ˆê±°ë‚˜ ì˜ë¯¸ì—†ëŠ” ê²°ê³¼ì¸ ê²½ìš° ì›ë³¸ ì‚¬ìš©
            if not safe_filename or safe_filename in [f"í‚¤ì›Œë“œì¶”ì¶œì‹¤íŒ¨{extension}", extension]:
                return original_filename
                
            return safe_filename
            
        except Exception as e:
            print(f"íŒŒì¼ëª… ì œì•ˆ ì¤‘ ì˜¤ë¥˜: {e}")
            return f"{original_name}{extension}"
    
    def _parse_keywords_from_response(self, response: str) -> str:
        """AI ì‘ë‹µì—ì„œ í‚¤ì›Œë“œë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤."""
        try:
            # ë¬´ì˜ë¯¸í•œ í‚¤ì›Œë“œ í•„í„°ë§ ëª©ë¡
            meaningless_keywords = {"ì—†ìŒ", "ë¹„ì–´ìˆìŒ", "ì•Œìˆ˜ì—†ìŒ", "ëª¨ë¦„", "ì •ë³´ì—†ìŒ", "ë‚´ìš©ì—†ìŒ", "ë¹ˆë‚´ìš©"}
            
            # "í‚¤ì›Œë“œ:" ë¼ë²¨ ì°¾ê¸° - ìƒˆë¡œìš´ íŒŒì¼ëª… í˜•ì‹ ì§€ì›
            keyword_match = re.search(r'í‚¤ì›Œë“œ\s*:\s*\[?([^\]\n]+)\]?', response, re.IGNORECASE)
            if keyword_match:
                keywords = keyword_match.group(1).strip()
                # íŠ¹ìˆ˜ë¬¸ì ì •ë¦¬ (ëŒ€ê´„í˜¸ ì œê±°, íŒŒì¼ëª…ì— ì í•©í•˜ì§€ ì•Šì€ ë¬¸ì)
                keywords = re.sub(r'[<>:"/\\|?*\[\]]', '', keywords)
                
                # ì™„ì „í•œ íŒŒì¼ëª… í˜•ì‹ì¸ì§€ í™•ì¸ (í™•ì¥ì í¬í•¨)
                if '.' in keywords and not keywords.startswith('.'):
                    # ì´ë¯¸ ì™„ì „í•œ íŒŒì¼ëª… í˜•ì‹
                    return keywords
                
                # í‚¤ì›Œë“œ í˜•ì‹ì¸ ê²½ìš° ë¬´ì˜ë¯¸í•œ í‚¤ì›Œë“œ í•„í„°ë§
                keyword_parts = [k.strip() for k in keywords.split('_') if k.strip()]
                filtered_parts = [k for k in keyword_parts if k not in meaningless_keywords]
                
                if len(filtered_parts) >= 1:  # ìµœì†Œ 1ê°œ ì´ìƒì˜ ì˜ë¯¸ìˆëŠ” í‚¤ì›Œë“œê°€ ìˆì„ ë•Œ ë°˜í™˜
                    return '_'.join(filtered_parts)
            
            # ëŒ€ì²´ íŒ¨í„´ë“¤ ì‹œë„
            lines = response.split('\n')
            for line in lines:
                if 'í‚¤ì›Œë“œ' in line and ':' in line:
                    keywords = line.split(':', 1)[1].strip()
                    keywords = re.sub(r'[<>:"/\\|?*\[\]]', '', keywords)
                    if keywords:
                        # ì™„ì „í•œ íŒŒì¼ëª… í˜•ì‹ì¸ì§€ í™•ì¸
                        if '.' in keywords and not keywords.startswith('.'):
                            return keywords
                        
                        # í‚¤ì›Œë“œ í˜•ì‹ì¸ ê²½ìš° ë¬´ì˜ë¯¸í•œ í‚¤ì›Œë“œ í•„í„°ë§
                        keyword_parts = [k.strip() for k in keywords.split('_') if k.strip()]
                        filtered_parts = [k for k in keyword_parts if k not in meaningless_keywords]
                        
                        if len(filtered_parts) >= 1:
                            return '_'.join(filtered_parts)
            
            # ì‘ë‹µì—ì„œ íŒŒì¼ëª… íŒ¨í„´ì„ ì§ì ‘ ì°¾ê¸° ì‹œë„
            filename_pattern = re.search(r'([a-zA-Zê°€-í£0-9_]+\.[a-zA-Z0-9]+)', response)
            if filename_pattern:
                return filename_pattern.group(1)
            
            return "í‚¤ì›Œë“œì¶”ì¶œì‹¤íŒ¨"
            
        except Exception:
            return "í‚¤ì›Œë“œì¶”ì¶œì‹¤íŒ¨"
    
    def _parse_folder_from_response(self, response: str) -> str:
        """AI ì‘ë‹µì—ì„œ í´ë”ëª…ì„ íŒŒì‹±í•©ë‹ˆë‹¤."""
        try:
            # "í´ë”:" ë¼ë²¨ ì°¾ê¸°
            folder_match = re.search(r'í´ë”\s*:\s*\[?([^\]\n]+)\]?', response, re.IGNORECASE)
            if folder_match:
                folder_name = folder_match.group(1).strip()
                # í´ë”ëª…ìœ¼ë¡œ ì í•©í•˜ì§€ ì•Šì€ ë¬¸ì ì œê±°
                folder_name = re.sub(r'[<>:"/\\|?*\[\]]', '', folder_name)
                return folder_name
            
            # ëŒ€ì²´ íŒ¨í„´ë“¤ ì‹œë„
            lines = response.split('\n')
            for line in lines:
                if 'í´ë”' in line and ':' in line:
                    folder_name = line.split(':', 1)[1].strip()
                    folder_name = re.sub(r'[<>:"/\\|?*\[\]]', '', folder_name)
                    if folder_name:
                        return folder_name
            
            return "ê¸°íƒ€"
            
        except Exception:
            return "ê¸°íƒ€"